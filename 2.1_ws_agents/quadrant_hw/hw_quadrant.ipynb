{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From REST to reasoning: ingest, index, and query with dlt and Cognee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.3\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "print(dlt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# get data\n",
    "@dlt.resource\n",
    "def zoomcamp_data():\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            yield doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlt.destinations import qdrant\n",
    "\n",
    "# we tell dlt (and Qdrant) to create a folder with our data, and the name for it will be db.qdrant\n",
    "qdrant_destination = qdrant(\n",
    "  qd_path=\"db.qdrant\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started at 2025-07-03 15:38:58.413240+00:00 and COMPLETED in 4.67 seconds with 4 steps.\n",
      "Step extract COMPLETED in 0.68 seconds.\n",
      "\n",
      "Load package 1751557138.9573472 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step normalize COMPLETED in 0.08 seconds.\n",
      "Normalized data for the following tables:\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "- zoomcamp_data: 948 row(s)\n",
      "\n",
      "Load package 1751557138.9573472 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step load COMPLETED in 3.37 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 3.35 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /Users/iuliia/projects/llm_zoomcamp/2.1_ws_agents/db.qdrant location to store data\n",
      "Load package 1751557138.9573472 is LOADED and contains no failed jobs\n",
      "\n",
      "Step run COMPLETED in 4.66 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 3.35 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /Users/iuliia/projects/llm_zoomcamp/2.1_ws_agents/db.qdrant location to store data\n",
      "Load package 1751557138.9573472 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"zoomcamp_pipeline\",\n",
    "    destination=qdrant_destination,\n",
    "    dataset_name=\"zoomcamp_tagged_data\"\n",
    "\n",
    ")\n",
    "load_info = pipeline.run(zoomcamp_data())\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many rows were inserted into the zoomcamp_data collection?**\n",
    "\n",
    "Normalized data for the following tables:\n",
    "- _dlt_pipeline_state: 1 row(s)\n",
    "- zoomcamp_data: 948 row(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When inserting the data, an embedding model was used. Which one?**\n",
    "\n",
    "You can find this out by inspecting the meta.json file created in the target folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('db.qdrant/meta.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectors': {'fast-bge-small-en': {'size': 384,\n",
       "   'distance': 'Cosine',\n",
       "   'hnsw_config': None,\n",
       "   'quantization_config': None,\n",
       "   'on_disk': None,\n",
       "   'datatype': None,\n",
       "   'multivector_config': None}},\n",
       " 'shard_number': None,\n",
       " 'sharding_method': None,\n",
       " 'replication_factor': None,\n",
       " 'write_consistency_factor': None,\n",
       " 'on_disk_payload': None,\n",
       " 'hnsw_config': None,\n",
       " 'wal_config': None,\n",
       " 'optimizers_config': None,\n",
       " 'init_from': None,\n",
       " 'quantization_config': None,\n",
       " 'sparse_vectors': None,\n",
       " 'strict_mode_config': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['collections']['zoomcamp_tagged_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
